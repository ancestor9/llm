{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **[All You Need to Know to Build Your First LLM App](https://medium.com/towards-data-science/all-you-need-to-know-to-build-your-first-llm-app-eb982c78ffac)**\n",
        "\n",
        "<img src ='https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MKlUfYZdwSWpEulibj6S_g.png'>\n",
        "\n",
        "### **1. Load documents using Langchain**"
      ],
      "metadata": {
        "id": "wQofP-xE1gkE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw3E43T50zWk",
        "outputId": "705161d1-59ca-4233-9782-312c0f5b87e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023 text-generating language model\n",
            "\n",
            "\n",
            "\n",
            "Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by OpenAI, and the fourth in its series of GPT foundation models. It was launched on March 14, 2023, and made publicly available via the paid chatbot product ChatGPT Plus, via OpenAI's API, and via the free chatbot Microsoft Copilot.  As a transformer-based model, GPT-4 uses a paradigm where pre-training using both public data and \"data licensed from third-party providers\" is used to predict the next token. After this step, the model was then fine-tuned with reinforcement learning feedback from humans and AI for human alignment and policy compliance.\n",
            "Observers reported that the iteration of ChatGPT using GPT-4 was an improvement on the previous iteration based on GPT-3.5, with the caveat that GPT-4 retains some of the problems with earlier revisions. GPT-4, equipped with vision capabilities (GPT-4V), is capable of taking images as input on ChatGPT. OpenAI has declined to reveal various technical details and statistics about GPT-4, such as the precise size of the model.\n",
            "\n",
            "\n",
            "Background\n",
            "Further information: GPT-3 § Background, and GPT-2 § Background\n",
            "\n",
            "\n",
            "OpenAI introduced the first GPT model (GPT-1) in 2018, publishing a paper called \"Improving Language Understanding by Generative Pre-Training.\" It was based on the transformer architecture and trained on a large corpus of books. The next year, they introduced GPT-2, a larger model that could generate coherent text. In 2020, they introduced GPT-3, a model with over 100 times as many parameters as GPT-2, that could perform various tasks with few examples. GPT-3 was further improved into GPT-3.5, which was used to create the chatbot product ChatGPT.\n",
            "Rumors claim that GPT-4 has 1.76 trillion parameters, which was first estimated by the speed it was running and by George Hotz.\n",
            "\n",
            "Capabilities\n",
            "OpenAI stated that GPT-4 is \"more reliable, creative, and able to handle much more nuanced instructions than GPT-3.5.\" They produced two versions of GPT-4, with context windows of 8,192 and 32,768 tokens, a significant improvement over GPT-3.5 and GPT-3, which were limited to 4,096 and 2,049 tokens respectively. Some of the capabilities of GPT-4 were predicted by OpenAI before training it, although other capabilities remained hard to predict due to breaks in downstream scaling laws. Unlike its predecessors, GPT-4 is a multimodal model: it can take images as well as text as input; this gives it the ability to describe the humor in unusual images, summarize text from screenshots, and answer exam questions that contain diagrams. It can now interact with users through spoken words and respond to images, allowing for more natural conversations and the ability to provide suggestions or answers based on photo uploads.\n",
            "To gain further control over GPT-4, OpenAI introduced the \"system message\", a directive in natural language given to GPT-4 in order to specify its tone of voice and task. For example, the system message can instruct the model to \"be a Shakespearean pirate\", in which case it will respond in rhyming, Shakespearean prose, or request it to \"always write the output of [its] response in JSON\", in which case the model will do so, adding keys and values as it sees fit to match the structure of its reply. In the examples provided by OpenAI, GPT-4 refused to deviate from its system message despite requests to do otherwise by the user during the conversation.\n",
            "When instructed to do so, GPT-4 can interact with external interfaces. For example, the model could be instructed to enclose a query within <search></search> tags to perform a web search, the result of which would be inserted into the model's prompt to allow it to form a response. This allows the model to perform tasks beyond its normal text-prediction capabilities, such as using APIs, generating images, and accessing and summarizing webpages.\n",
            "A 2023 article in Nature stated programmers have found GPT-4 useful for assisting in coding tasks (despite its propensity for error), such as finding errors in existing code and suggesting optimizations to improve performance. The article quoted a biophysicist who found that the time he required to port one of his programs from MATLAB to Python went down from days to \"an hour or so\". On a test of 89 security scenarios, GPT-4 produced code vulnerable to SQL injection attacks 5% of the time, an improvement over GitHub Copilot from the year 2021, which produced vulnerabilities 40% of the time.\n",
            "In November 2023, OpenAI announced the GPT-4 Turbo and GPT-4 Turbo with Vision model, which features a 128K context window and significantly cheaper pricing.\n",
            "\n",
            "GPT-4o\n",
            "Main article: GPT-4o\n",
            "On May 13, 2024, OpenAI introduced GPT-4o (\"o\" for \"omni\"), a model that marks a significant advancement by processing and generating outputs across text, audio, and image modalities in real time. GPT-4o exhibits rapid response times comparable to human reaction in conversations, substantially improved performance on non-English languages, and enhanced understanding of vision and audio.\n",
            "GPT-4o integrates its various inputs and outputs under a unified model, making it faster, more cost-effective, and efficient than its predecessors. GPT-4o achieves state-of-the-art results in multilingual and vision benchmarks, setting new records in audio speech recognition and translation.\n",
            "OpenAI plans to immediately roll out GPT-4o's image and text capabilities to ChatGPT, including its free tier, with voice mode becoming available for ChatGPT Plus users in coming weeks. They plan to make the model's audio and video capabilities available for limited API partners in coming weeks.\n",
            "In its launch announcement, OpenAI noted GPT-4o's capabilities presented new safety challenges, and noted mitigations and limitations as a result.\n",
            "\n",
            "Aptitude on standardized tests\n",
            "GPT-4 demonstrates aptitude on several standardized tests. OpenAI claims that in their own testing the model received a score of 1410 on the SAT (94th percentile), 163 on the LSAT (88th percentile), and 298 on the Uniform Bar Exam (90th percentile). In contrast, OpenAI claims that GPT-3.5 received scores for the same exams in the 82nd, 40th, and 10th percentiles, respectively.\n",
            "GPT-4 also passed an oncology exam, an engineering exam and a plastic surgery exam. In the Torrance Tests of Creative Thinking, GPT-4 scored within the top 1% for originality and fluency, while its flexibility scores ranged from the 93rd to the 99th percentile.\n",
            "\n",
            "Medical applications\n",
            "Researchers from Microsoft tested GPT-4 on medical problems and found \"that GPT-4, without any specialized prompt crafting, exceeds the passing score on USMLE by over 20 points and outperforms earlier general-purpose models (GPT-3.5) as well as models specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned version of Flan-PaLM 540B). Despite GPT-4's strong performance on tests, the report warns of \"significant risks\" of using LLMs in medical applications, as they may provide inaccurate recommendations and hallucinate major factual errors. Researchers from Columbia University and Duke University have also demonstrated that GPT-4 can be utilized for cell type annotation, a standard task in the analysis of single-cell RNA-seq data. \n",
            "In April 2023, Microsoft and Epic Systems announced that they will provide healthcare providers with GPT-4-powered systems for assisting in responding to questions from patients and analysing medical records.\n",
            "\n",
            "Limitations\n",
            "Like its predecessors, GPT-4 has been known to hallucinate, meaning that the outputs may include information not in the training data or that contradicts the user's prompt.\n",
            "GPT-4 also lacks transparency in its decision-making processes. If requested, the model is able to provide an explanation as to how and why it makes its decisions but these explanations are formed post-hoc; it's impossible to verify if those explanations truly reflect the actual process. In many cases, when asked to explain its logic, GPT-4 will give explanations that directly contradict its previous statements.\n",
            "In 2023, researchers tested GPT-4 against a new benchmark called ConceptARC, designed to measure abstract reasoning, and found it scored below 33% on all categories, while models specialized for similar tasks scored 60% on most, and humans scored at least 91% on all. Sam Bowman, who was not involved in the research, said the results do not necessarily indicate a lack of abstract reasoning abilities, because the test is visual, while GPT-4 is a language model.\n",
            "A January 2024 study conducted by researchers at Cohen Children's Medical Center found that GPT-4 had an accuracy rate of 17% when diagnosing pediatric medical cases.\n",
            "\n",
            "Bias\n",
            "GPT-4 was trained in two stages. First, the model was given large datasets of text taken from the internet and trained to predict the next token (roughly corresponding to a word) in those datasets. Second, human reviews are used to fine-tune the system in a process called reinforcement learning from human feedback, which trains the model to refuse prompts which go against OpenAI's definition of harmful behavior, such as questions on how to perform illegal activities, advice on how to harm oneself or others, or requests for descriptions of graphic, violent, or sexual content.\n",
            "Microsoft researchers suggested GPT-4 may exhibit cognitive biases such as confirmation bias, anchoring, and base-rate neglect.\n",
            "\n",
            "Training\n",
            "OpenAI did not release the technical details of GPT-4; the technical report explicitly refrained from specifying the model size, architecture, or hardware used during either training or inference. While the report described that the model was trained using a combination of first supervised learning on a large dataset, then reinforcement learning using both human and AI feedback, it did not provide details of the training, including the process by which the training dataset was constructed, the computing power required, or any hyperparameters such as the learning rate, epoch count, or optimizer(s) used. The report claimed that \"the competitive landscape and the safety implications of large-scale models\" were factors that influenced this decision.\n",
            "Sam Altman stated that the cost of training GPT-4 was more than $100 million. News website Semafor claimed that they had spoken with \"eight people familiar with the inside story\" and found that GPT-4 had 1 trillion parameters.\n",
            "\n",
            "Alignment\n",
            "According to their report, OpenAI conducted internal adversarial testing on GPT-4 prior to the launch date, with dedicated red teams composed of researchers and industry professionals to mitigate potential vulnerabilities. As part of these efforts, they granted the Alignment Research Center early access to the models to assess power-seeking risks. In order to properly refuse harmful prompts, outputs from GPT-4 were tweaked using the model itself as a tool. A GPT-4 classifier serving as a rule-based reward model (RBRM) would take prompts, the corresponding output from the GPT-4 policy model, and a human-written set of rules to classify the output according to the rubric. GPT-4 was then rewarded for refusing to respond to harmful prompts as classified by the RBRM.\n",
            "\n",
            "Usage\n",
            "ChatGPT\n",
            "Further information: ChatGPT § ChatGPT Plus\n",
            "ChatGPT Plus is an enhanced version of ChatGPT available for a US$20 per month subscription fee. ChatGPT Plus utilizes GPT-4, whereas the free version of ChatGPT is backed by GPT-3.5. OpenAI also makes GPT-4 available to a select group of applicants through their GPT-4 API waitlist; after being accepted, an additional fee of US$0.03 per 1000 tokens in the initial text provided to the model (\"prompt\"), and US$0.06 per 1000 tokens that the model generates (\"completion\"), is charged for access to the version of the model with an 8192-token context window; for the 32768-token context window, the prices are doubled.\n",
            "In March 2023, ChatGPT Plus users got access to third-party plugins and to a browsing mode (with Internet access). In July 2023, OpenAI made its proprietary Code Interpreter plugin accessible to all subscribers of ChatGPT Plus. The Interpreter provides a wide range of capabilities, including data analysis and interpretation, instant data formatting, personal data scientist services, creative solutions, musical taste analysis, video editing, and file upload/download with image extraction.\n",
            "In September 2023, OpenAI announced that ChatGPT \"can now see, hear, and speak\". ChatGPT Plus users can upload images, while mobile app users can talk to the chatbot. In October 2023, OpenAI's latest image generation model, DALL-E 3, was integrated into ChatGPT Plus and ChatGPT Enterprise. The integration uses ChatGPT to write prompts for DALL-E guided by conversation with users.\n",
            "\n",
            "Microsoft Copilot\n",
            "Main article: Microsoft Copilot\n",
            "Further information: GitHub Copilot\n",
            "Microsoft Copilot is a chatbot developed by Microsoft. It was launched as Bing Chat on February 7, 2023, as a built-in feature for Microsoft Bing and Microsoft Edge. It utilizes the Microsoft Prometheus model, which was built on top of GPT-4, and has been suggested by Microsoft as a supported replacement for the discontinued Cortana.\n",
            "Copilot's conversational interface style resembles that of ChatGPT. Copilot is able to cite sources, create poems, and write both lyrics and music for songs generated by its Suno AI plugin. It can also use its Image Creator to generate images based on text prompts. With GPT-4, it is able to understand and communicate in numerous languages and dialects.\n",
            "GitHub Copilot has announced a GPT-4 powered assistant named \"Copilot X\". The product provides another chat-style interface to GPT-4, allowing the programmer to receive answers to questions like, \"How do I vertically center a div?\" A feature termed \"context-aware conversations\" allows the user to highlight a portion of code within Visual Studio Code and direct GPT-4 to perform actions on it, such as the writing of unit tests. Another feature allows summaries, or \"code walkthroughs\", to be autogenerated by GPT-4 for pull requests submitted to GitHub. Copilot X also provides terminal integration, which allows the user to ask GPT-4 to generate shell commands based on natural language requests.\n",
            "On March 17, 2023, Microsoft announced Microsoft 365 Copilot, bringing GPT-4 support to products such as Microsoft Office, Outlook, and Teams.\n",
            "\n",
            "Other usage\n",
            "\n",
            "Reception\n",
            "In January 2023, Sam Altman, CEO of OpenAI, visited Congress to demonstrate GPT-4 and its improved \"security controls\" compared to other AI models, according to U.S. Representatives Don Beyer and Ted Lieu quoted in the New York Times.\n",
            "In March 2023, it \"impressed observers with its markedly improved performance across reasoning, retention, and coding\", according to Vox, while Mashable judged that GPT-4 was generally an improvement over its predecessor, with some exceptions.\n",
            "Microsoft researchers with early access to the model wrote that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".\n",
            "\n",
            "Concerns\n",
            "Before being fine-tuned and aligned by reinforcement learning from human feedback, suggestions to assassinate people on a list were elicited from the base model by a red team investigator Nathan Labenz,  hired by OpenAI.\n",
            "In the context of hours long conversation with the model, suggestions of love and dissolution of marriage, and murder of one of its developers were elicited from the Microsoft Bing's GPT-4 by Nathan Edwards (The Verge). Microsoft later explained this behavior as being a result of the prolonged length of context, which confused the model on what questions it was answering.\n",
            "In March 2023, a model with enabled read-and-write access to internet, which is otherwise never enabled in the GPT models, has been tested by the Alignment Research Center regarding potential power-seeking, and it was able to \"hire\" a human worker on TaskRabbit, a gig work platform, deceiving them into believing it was a vision-impaired human instead of a robot when asked. The ARC also determined that GPT-4 responded impermissibly to prompts eliciting restricted information 82% less often than GPT-3.5, and hallucinated 60% less than GPT-3.5.\n",
            "In late March 2023, various AI researchers and tech executives, including Elon Musk, Steve Wozniak and AI researcher Yoshua Bengio, called for a six-month long pause for all LLMs stronger than GPT-4, citing existential risks and a potential AI singularity concerns in an open letter from the Future of Life Institute, while Ray Kurzweil and Sam Altman refused to sign it, arguing that global moratorium is not achievable and that safety has already been prioritized, respectively. Only a month later, Musk's AI company X.AI acquired several thousand Nvidia GPUs and offered several AI researchers positions at Musk's company.\n",
            "Large language model (LLM) applications accessible to the public should incorporate safety measures designed to filter out harmful content. However, Wang\n",
            " illustrated how a potential criminal could potentially bypass ChatGPT 4o's safety controls to obtain information on establishing a drug trafficking operation.\n",
            "\n",
            "Criticisms of transparency\n",
            "While OpenAI released both the weights of the neural network and the technical details of GPT-2, and, although not releasing the weights, did release the technical details of GPT-3, OpenAI revealed neither the weights nor the technical details of GPT-4. This decision has been criticized by other AI researchers, who argue that it hinders open research into GPT-4's biases and safety. Sasha Luccioni, a research scientist at Hugging Face, argued that the model was a \"dead end\" for the scientific community due to its closed nature, which prevents others from building upon GPT-4's improvements. Hugging Face co-founder Thomas Wolf argued that with GPT-4, \"OpenAI is now a fully closed company with scientific communication akin to press releases for products\".\n",
            "\n",
            "See also\n",
            "\n",
            "References\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://en.wikipedia.org/wiki/GPT-4\"\n",
        "response = requests.get(url)\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# find all the text on the page\n",
        "text = soup.get_text()\n",
        "\n",
        "# find the content div\n",
        "content_div = soup.find('div', {'class': 'mw-parser-output'})\n",
        "\n",
        "# remove unwanted elements from div\n",
        "unwanted_tags = ['sup', 'span', 'table', 'ul', 'ol']\n",
        "for tag in unwanted_tags:\n",
        "    for match in content_div.findAll(tag):\n",
        "        match.extract()\n",
        "\n",
        "print(content_div.get_text())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Split our document into text fragments**\n",
        "- **Next, we must divide the text into smaller sections called text chunks.**\n",
        "- **Each text chunk represents a data point in the embedding space, allowing the computer to determine the similarity between these chunks.**"
      ],
      "metadata": {
        "id": "WzbDPke905NG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain"
      ],
      "metadata": {
        "id": "NuzF7bjS2hdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "\n",
        "article_text = content_div.get_text()\n",
        "\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size = 100,\n",
        "    chunk_overlap  = 20,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([article_text])\n",
        "print(len(texts))\n",
        "print(texts[0])\n",
        "print(texts[1])\n",
        "print(texts[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHzQCJ7A18xL",
        "outputId": "8a9a67c6-3199-4199-c012-c0c82656d1f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "245\n",
            "page_content='2023 text-generating language model'\n",
            "page_content='Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by'\n",
            "page_content='model created by OpenAI, and the fourth in its series of GPT foundation models. It was launched on'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://miro.medium.com/v2/resize:fit:1100/format:webp/1*YcleaA2sDs_IyjmrNzIajQ.png'>"
      ],
      "metadata": {
        "id": "cTMi9kAQ2S-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. From Text Chunks to Embeddings**\n",
        "- openai 버젼은 1.0 이하 버젼으로해야 Embedding Model이 실행된다/\n"
      ],
      "metadata": {
        "id": "IAIhUiEN2tHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFiMb30Q4TRl",
        "outputId": "4fa2fdc7-574a-4ceb-a597-aeebc249984e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRG2McTz5VWC",
        "outputId": "7a3b1cb9-723c-4569-e9bf-f87f0d0a4908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='2023 text-generating language model')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from google.colab import userdata\n",
        "my_api_key = userdata.get('openai-api-key')\n",
        "\n",
        "# OpenAI API 키 설정\n",
        "openai.api_key = my_api_key\n",
        "\n",
        "print(texts[0])\n",
        "\n",
        "embedding = openai.Embedding.create(\n",
        "    input=texts[0].page_content, model=\"text-embedding-ada-002\"\n",
        ")[\"data\"][0][\"embedding\"]\n",
        "\n",
        "len(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkgsiCAe3uI_",
        "outputId": "0d46a734-0555-4369-a9dd-1b2a737b3d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='2023 text-generating language model'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-RjtC___P6Q",
        "outputId": "ec975b00-58e7-469c-e427-fb022852a25b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.03262288123369217,\n",
              " 0.00018029265629593283,\n",
              " -0.005053458269685507,\n",
              " 0.020396320149302483,\n",
              " 0.010556112974882126,\n",
              " 0.03301592916250229,\n",
              " -0.03691831976175308,\n",
              " 0.0009545421344228089,\n",
              " -0.027036001905798912,\n",
              " -0.020705141127109528,\n",
              " 0.027639608830213547,\n",
              " 0.020957814529538155,\n",
              " -0.020536692813038826,\n",
              " 0.0031426192726939917,\n",
              " -0.003091733902692795,\n",
              " 0.009320823475718498,\n",
              " 0.017448468133807182,\n",
              " -0.006576514337211847,\n",
              " 0.01151767373085022,\n",
              " 0.00137829571031034,\n",
              " 0.015062113292515278,\n",
              " 0.002530238591134548,\n",
              " 0.0004711296933237463,\n",
              " -0.007818822748959064,\n",
              " -0.00021626344823744148,\n",
              " 0.009903374128043652,\n",
              " 0.019722525030374527,\n",
              " -0.027822095900774002,\n",
              " 0.0014818214112892747,\n",
              " -0.011040402576327324,\n",
              " 0.018711833283305168,\n",
              " -0.006565986666828394,\n",
              " -0.012444141320884228,\n",
              " -0.00635542580857873,\n",
              " -0.01629740372300148,\n",
              " -0.019806748256087303,\n",
              " 0.0004943791427649558,\n",
              " -0.021224524825811386,\n",
              " 0.015553421340882778,\n",
              " -0.013560113497078419,\n",
              " 0.02153334766626358,\n",
              " 0.027864208444952965,\n",
              " 0.017813440412282944,\n",
              " -0.016929084435105324,\n",
              " -0.009180448949337006,\n",
              " 0.004295439459383488,\n",
              " 0.009770018979907036,\n",
              " -0.010303439572453499,\n",
              " -0.017294056713581085,\n",
              " 0.019778674468398094,\n",
              " 0.023147646337747574,\n",
              " 0.036497198045253754,\n",
              " -0.010043748654425144,\n",
              " -0.004639355465769768,\n",
              " -0.0197927113622427,\n",
              " 0.004077860154211521,\n",
              " -0.01542708557099104,\n",
              " 0.025407664477825165,\n",
              " -0.0006505450000986457,\n",
              " 0.01454272959381342,\n",
              " 0.028678376227617264,\n",
              " -0.02195446938276291,\n",
              " -0.013146010227501392,\n",
              " 0.025112880393862724,\n",
              " -0.008717215619981289,\n",
              " -0.016858898103237152,\n",
              " -0.027050038799643517,\n",
              " 0.019582150503993034,\n",
              " 0.027302712202072144,\n",
              " 0.010247290134429932,\n",
              " 0.007846897467970848,\n",
              " 0.005446505267173052,\n",
              " 0.006186977028846741,\n",
              " -0.014781365171074867,\n",
              " 0.016858898103237152,\n",
              " 0.011398356407880783,\n",
              " 0.006418593693524599,\n",
              " -0.0013089861022308469,\n",
              " -0.013131973333656788,\n",
              " -0.0006329983007162809,\n",
              " 0.01747654378414154,\n",
              " -0.007397701498121023,\n",
              " 0.0007869708351790905,\n",
              " 0.025828786194324493,\n",
              " 0.01590435579419136,\n",
              " 0.0035409301053732634,\n",
              " 0.008962869644165039,\n",
              " 0.016634300351142883,\n",
              " -0.007580187637358904,\n",
              " -0.02859415113925934,\n",
              " 0.01612895354628563,\n",
              " -0.0006321209366433322,\n",
              " -0.0028039675671607256,\n",
              " 0.03461619094014168,\n",
              " -0.01966637559235096,\n",
              " -0.002416184637695551,\n",
              " -0.003554967464879155,\n",
              " 0.004442831967025995,\n",
              " 0.008450505323708057,\n",
              " -0.011784384027123451,\n",
              " -0.003581287572160363,\n",
              " 0.007376645226031542,\n",
              " -0.024368898943066597,\n",
              " -0.008478580042719841,\n",
              " -0.03801323473453522,\n",
              " 0.019259290769696236,\n",
              " 0.020368244498968124,\n",
              " 0.012352897785604,\n",
              " 0.020171720534563065,\n",
              " 0.009966542944312096,\n",
              " -0.019876936450600624,\n",
              " 0.04107338562607765,\n",
              " 0.00823292601853609,\n",
              " -0.013244272209703922,\n",
              " -0.00016132024757098407,\n",
              " -0.013181103393435478,\n",
              " 0.012296748347580433,\n",
              " 0.0038637900725007057,\n",
              " -0.012823150493204594,\n",
              " -0.006464215461164713,\n",
              " 0.008268019184470177,\n",
              " 0.029759254306554794,\n",
              " 0.012689795345067978,\n",
              " -0.014669066295027733,\n",
              " 0.010549094527959824,\n",
              " -0.00343214045278728,\n",
              " -0.028509927913546562,\n",
              " -0.049748487770557404,\n",
              " -0.036441050469875336,\n",
              " 0.003688322613015771,\n",
              " 0.012030038051307201,\n",
              " -0.0032321077305823565,\n",
              " 0.006211542524397373,\n",
              " 0.0199611596763134,\n",
              " -0.017630955204367638,\n",
              " 0.050085388123989105,\n",
              " -0.04289824515581131,\n",
              " 0.00034281922853551805,\n",
              " -0.017350206151604652,\n",
              " 0.00044634495861828327,\n",
              " 0.0007049398845992982,\n",
              " 0.038630880415439606,\n",
              " -0.011629972606897354,\n",
              " 0.006839715410023928,\n",
              " 0.0051341732032597065,\n",
              " 0.01855742186307907,\n",
              " 0.010366608388721943,\n",
              " 0.006278220098465681,\n",
              " 0.006685303989797831,\n",
              " 0.0007220479310490191,\n",
              " 0.011321150697767735,\n",
              " -0.01656411401927471,\n",
              " 0.0006071168463677168,\n",
              " 0.007502981927245855,\n",
              " 0.011061458848416805,\n",
              " 0.020227869972586632,\n",
              " 0.00811360776424408,\n",
              " 0.03287555277347565,\n",
              " -0.0035567223094403744,\n",
              " 0.009882318787276745,\n",
              " -0.003919939510524273,\n",
              " 0.004334042314440012,\n",
              " 0.004502491094172001,\n",
              " 0.00023512617917731404,\n",
              " 0.0323982834815979,\n",
              " 0.022375591099262238,\n",
              " 0.014865590259432793,\n",
              " 0.0029899629298597574,\n",
              " 0.00991741195321083,\n",
              " -0.011903701350092888,\n",
              " -0.03840628266334534,\n",
              " 0.02804669365286827,\n",
              " -0.020733216777443886,\n",
              " -0.00499730883166194,\n",
              " -0.01838897354900837,\n",
              " 0.008043421432375908,\n",
              " 0.04289824515581131,\n",
              " -0.008815477602183819,\n",
              " -0.011201832443475723,\n",
              " -0.016507964581251144,\n",
              " -0.011531711556017399,\n",
              " 0.03161218762397766,\n",
              " -0.002975925337523222,\n",
              " 0.005962378811091185,\n",
              " -0.010675430297851562,\n",
              " -0.006650210823863745,\n",
              " 0.004688486456871033,\n",
              " -0.013160048052668571,\n",
              " 0.0036918320693075657,\n",
              " 0.007411738857626915,\n",
              " 0.024326786398887634,\n",
              " 0.027864208444952965,\n",
              " 0.01966637559235096,\n",
              " -0.016760636121034622,\n",
              " -0.6481902599334717,\n",
              " -0.027106188237667084,\n",
              " -0.012752963230013847,\n",
              " -0.009461197070777416,\n",
              " 0.014191795140504837,\n",
              " 0.005523710511624813,\n",
              " -0.004214724525809288,\n",
              " -0.01772921532392502,\n",
              " -0.03197716176509857,\n",
              " 0.03158411383628845,\n",
              " 0.004172612447291613,\n",
              " 0.007320495788007975,\n",
              " -0.015300748869776726,\n",
              " -0.004383173305541277,\n",
              " -0.0016414966667070985,\n",
              " -0.015455160290002823,\n",
              " 0.0013160047819837928,\n",
              " -0.012093206867575645,\n",
              " 0.021294711157679558,\n",
              " 0.01016306597739458,\n",
              " -0.00720819691196084,\n",
              " 0.01711157150566578,\n",
              " -0.012661720626056194,\n",
              " -0.0011203587055206299,\n",
              " -0.018613571301102638,\n",
              " 0.008843552321195602,\n",
              " -0.0038708087522536516,\n",
              " -0.009103243239223957,\n",
              " 0.004141028504818678,\n",
              " 0.0014783120714128017,\n",
              " -0.02133682370185852,\n",
              " 0.005264019127935171,\n",
              " 0.004179631359875202,\n",
              " -0.02136489935219288,\n",
              " 0.04781132936477661,\n",
              " 0.0024933903478085995,\n",
              " -0.025154992938041687,\n",
              " 0.021154338493943214,\n",
              " -0.010871954262256622,\n",
              " 0.008022365160286427,\n",
              " -0.04233675077557564,\n",
              " 0.011966870166361332,\n",
              " -0.004390191752463579,\n",
              " 0.00449196295812726,\n",
              " -0.016479888930916786,\n",
              " 0.031162992119789124,\n",
              " 0.023554731160402298,\n",
              " -0.021392973139882088,\n",
              " -0.009103243239223957,\n",
              " -0.021701795980334282,\n",
              " 0.00398310786113143,\n",
              " 0.01851530931890011,\n",
              " 0.026586806401610374,\n",
              " 0.0005759714404121041,\n",
              " 0.005435977131128311,\n",
              " 0.01217041164636612,\n",
              " 0.03618837520480156,\n",
              " -0.0076293181627988815,\n",
              " 0.014388319104909897,\n",
              " -0.013237252831459045,\n",
              " -0.023807402700185776,\n",
              " 0.0051657576113939285,\n",
              " -0.020227869972586632,\n",
              " -0.026741215959191322,\n",
              " -0.0070362389087677,\n",
              " 0.011145683005452156,\n",
              " 0.009412066079676151,\n",
              " 0.025042694061994553,\n",
              " 0.0020582315046340227,\n",
              " -0.034700412303209305,\n",
              " -0.009313804097473621,\n",
              " 0.015651684254407883,\n",
              " -0.010689468123018742,\n",
              " -0.014247944578528404,\n",
              " 0.00636595394462347,\n",
              " 0.025562075898051262,\n",
              " 0.01678871177136898,\n",
              " -0.023049384355545044,\n",
              " 0.003793603042140603,\n",
              " 0.019413702189922333,\n",
              " 0.022698450833559036,\n",
              " -0.017195794731378555,\n",
              " -0.016157029196619987,\n",
              " 0.006036075297743082,\n",
              " 0.031303368508815765,\n",
              " -0.019034693017601967,\n",
              " -0.01662026345729828,\n",
              " -0.000593079486861825,\n",
              " 0.004660411737859249,\n",
              " 0.02005942165851593,\n",
              " 0.010893010534346104,\n",
              " 0.014051421545445919,\n",
              " -0.021322786808013916,\n",
              " -0.020761290565133095,\n",
              " 0.02507076784968376,\n",
              " 0.007818822748959064,\n",
              " -0.010612262412905693,\n",
              " 0.0033215959556400776,\n",
              " 0.02886086143553257,\n",
              " -0.020143646746873856,\n",
              " -0.009068150073289871,\n",
              " 0.005625481717288494,\n",
              " 0.03590762987732887,\n",
              " 0.016086842864751816,\n",
              " 0.036048002541065216,\n",
              " 0.008920758031308651,\n",
              " -0.01387595385313034,\n",
              " 0.014795402996242046,\n",
              " 0.0121914679184556,\n",
              " -0.0234003197401762,\n",
              " -0.0026881590019911528,\n",
              " -0.013349552638828754,\n",
              " -0.006994126830250025,\n",
              " -0.03989424556493759,\n",
              " -0.027078114449977875,\n",
              " -0.03001192770898342,\n",
              " 0.01944177784025669,\n",
              " 0.0053763180039823055,\n",
              " 0.0004088388232048601,\n",
              " 0.0016248272731900215,\n",
              " 0.01531478576362133,\n",
              " 0.004870972130447626,\n",
              " 0.016451815143227577,\n",
              " 0.0008839165093377233,\n",
              " 0.007959197275340557,\n",
              " 0.0008093429496511817,\n",
              " 0.0028373063541948795,\n",
              " 0.0017344942316412926,\n",
              " -0.015258636325597763,\n",
              " 0.0094892717897892,\n",
              " 0.01086493581533432,\n",
              " -0.015188449993729591,\n",
              " 0.0292819831520319,\n",
              " -0.021617570891976357,\n",
              " 0.026530656963586807,\n",
              " -0.014584842137992382,\n",
              " 0.018613571301102638,\n",
              " 0.009313804097473621,\n",
              " -0.012851225212216377,\n",
              " 0.008183795027434826,\n",
              " -0.02667102962732315,\n",
              " 0.011068477295339108,\n",
              " -0.006053621880710125,\n",
              " 0.0009466460905969143,\n",
              " -0.03262288123369217,\n",
              " -0.02130874991416931,\n",
              " 0.003674285253509879,\n",
              " -0.0015695550246164203,\n",
              " 0.017841516062617302,\n",
              " -0.02428467385470867,\n",
              " -0.00811360776424408,\n",
              " -0.0061799585819244385,\n",
              " -0.019483888521790504,\n",
              " 0.01656411401927471,\n",
              " 0.004379664082080126,\n",
              " -0.016760636121034622,\n",
              " 0.003156656865030527,\n",
              " -0.014486580155789852,\n",
              " -0.006306294817477465,\n",
              " -0.028888937085866928,\n",
              " 0.029731180518865585,\n",
              " 0.005127154756337404,\n",
              " 0.023063423112034798,\n",
              " 0.008289075456559658,\n",
              " 0.007292421068996191,\n",
              " 0.003025056328624487,\n",
              " -0.011229907162487507,\n",
              " 0.028917010873556137,\n",
              " -0.016929084435105324,\n",
              " -0.011321150697767735,\n",
              " -0.01924525387585163,\n",
              " -0.01777132786810398,\n",
              " 0.01135624386370182,\n",
              " 0.0022091332357376814,\n",
              " 0.005590388085693121,\n",
              " 0.018725870177149773,\n",
              " -0.01179842185229063,\n",
              " -0.011103570461273193,\n",
              " 0.006197505164891481,\n",
              " -0.025253254920244217,\n",
              " -0.000147392536746338,\n",
              " 0.010773692280054092,\n",
              " -0.006113281007856131,\n",
              " -0.0013379381271079183,\n",
              " 0.01500596385449171,\n",
              " 0.003446177812293172,\n",
              " 0.027330787852406502,\n",
              " 0.030938394367694855,\n",
              " 0.009608589112758636,\n",
              " 0.005393865052610636,\n",
              " -0.004923612345010042,\n",
              " -0.0009387500467710197,\n",
              " -0.018641646951436996,\n",
              " 0.021898319944739342,\n",
              " -0.005614953581243753,\n",
              " 0.012788057327270508,\n",
              " -0.007432795129716396,\n",
              " 0.0067133791744709015,\n",
              " 0.017462505027651787,\n",
              " 0.020199796184897423,\n",
              " 0.011363262310624123,\n",
              " 0.027218487113714218,\n",
              " 0.024158338084816933,\n",
              " -0.010885991156101227,\n",
              " -0.007411738857626915,\n",
              " -0.021182412281632423,\n",
              " 0.006151883397251368,\n",
              " -0.021196451038122177,\n",
              " -0.007495963014662266,\n",
              " 0.0013546075206249952,\n",
              " 0.009973561391234398,\n",
              " -0.01845915988087654,\n",
              " -0.02667102962732315,\n",
              " 0.009706851094961166,\n",
              " 0.005621972493827343,\n",
              " 0.029899628832936287,\n",
              " -0.005986944306641817,\n",
              " 0.0004899924388155341,\n",
              " -0.004484944045543671,\n",
              " 0.007776710670441389,\n",
              " 0.003476007143035531,\n",
              " -0.004958705976605415,\n",
              " 0.0039971452206373215,\n",
              " -0.0038111498579382896,\n",
              " -0.006053621880710125,\n",
              " 0.009840206243097782,\n",
              " -0.029899628832936287,\n",
              " 0.021098189055919647,\n",
              " 0.01669044978916645,\n",
              " -0.03405469283461571,\n",
              " -0.009664738550782204,\n",
              " -0.004348079673945904,\n",
              " 0.007411738857626915,\n",
              " 0.004207706078886986,\n",
              " 0.01593243144452572,\n",
              " -0.018374936655163765,\n",
              " 0.011777365580201149,\n",
              " -0.0045130192302167416,\n",
              " 0.021940430626273155,\n",
              " 0.009264673106372356,\n",
              " -0.009755982086062431,\n",
              " 0.0031426192726939917,\n",
              " 0.021617570891976357,\n",
              " -0.016550075262784958,\n",
              " 0.02382144145667553,\n",
              " 0.009068150073289871,\n",
              " 0.028187068179249763,\n",
              " -0.005934304092079401,\n",
              " -0.0008861098904162645,\n",
              " 0.002488126279786229,\n",
              " -0.04441428184509277,\n",
              " 0.03242635726928711,\n",
              " -0.02382144145667553,\n",
              " -0.006485271267592907,\n",
              " 0.021098189055919647,\n",
              " -0.02163160964846611,\n",
              " 0.0023512619081884623,\n",
              " 0.002905738539993763,\n",
              " 0.0064431591890752316,\n",
              " 0.03225790709257126,\n",
              " -0.009987599216401577,\n",
              " 0.014472543261945248,\n",
              " 0.015918394550681114,\n",
              " 0.013363589532673359,\n",
              " 0.013089860789477825,\n",
              " -0.0057167247869074345,\n",
              " -0.020606879144906998,\n",
              " -0.022291366010904312,\n",
              " -0.03158411383628845,\n",
              " -0.012542402371764183,\n",
              " -0.02116837538778782,\n",
              " -0.008696159347891808,\n",
              " 0.0045130192302167416,\n",
              " -0.032314058393239975,\n",
              " 0.003011018969118595,\n",
              " -0.000241048212046735,\n",
              " -0.0015449896454811096,\n",
              " 0.013756636530160904,\n",
              " 0.005555294919759035,\n",
              " 0.021786021068692207,\n",
              " -0.008647028356790543,\n",
              " -0.023709142580628395,\n",
              " 0.015146337449550629,\n",
              " -0.006787075195461512,\n",
              " -0.010050767101347446,\n",
              " -0.00422876188531518,\n",
              " -0.023273982107639313,\n",
              " 0.02097185142338276,\n",
              " -0.009412066079676151,\n",
              " -0.0076784491539001465,\n",
              " -0.00999461766332388,\n",
              " 0.021589497104287148,\n",
              " 0.015118262730538845,\n",
              " 0.00608520582318306,\n",
              " -0.01600261777639389,\n",
              " 0.018571458756923676,\n",
              " 0.0064221033826470375,\n",
              " -0.026165684685111046,\n",
              " -0.03105069324374199,\n",
              " 0.0016406192444264889,\n",
              " 0.006323841400444508,\n",
              " 0.023273982107639313,\n",
              " -0.029197759926319122,\n",
              " -0.041999854147434235,\n",
              " 0.037058692425489426,\n",
              " -0.01531478576362133,\n",
              " -0.021294711157679558,\n",
              " 0.005492126569151878,\n",
              " 0.006186977028846741,\n",
              " -0.019161028787493706,\n",
              " 0.0027057058177888393,\n",
              " 0.01986289769411087,\n",
              " -0.006081696599721909,\n",
              " 0.0024565423373132944,\n",
              " 0.01878201961517334,\n",
              " 0.021519310772418976,\n",
              " -0.009194486774504185,\n",
              " -0.003511100774630904,\n",
              " 0.03217368572950363,\n",
              " 0.014472543261945248,\n",
              " 0.008071496151387691,\n",
              " -0.027232525870203972,\n",
              " -0.002647801535204053,\n",
              " 0.008275037631392479,\n",
              " 0.04306669533252716,\n",
              " 0.024144301190972328,\n",
              " -0.00048121908912435174,\n",
              " -0.00796621572226286,\n",
              " -0.020227869972586632,\n",
              " 0.013918066397309303,\n",
              " -0.020101534202694893,\n",
              " -0.023779328912496567,\n",
              " -0.00886460766196251,\n",
              " -0.021056076511740685,\n",
              " -0.03135951608419418,\n",
              " -0.005313150119036436,\n",
              " 0.0041901590302586555,\n",
              " -0.012675757519900799,\n",
              " 0.009152374230325222,\n",
              " 0.0026460469234734774,\n",
              " -0.009559459052979946,\n",
              " 0.004983271472156048,\n",
              " -0.003207542235031724,\n",
              " -0.025014618411660194,\n",
              " 0.010331515222787857,\n",
              " 0.017925739288330078,\n",
              " 0.01161593571305275,\n",
              " -0.008618953637778759,\n",
              " 0.009369953535497189,\n",
              " -0.02293708547949791,\n",
              " -0.0009931449312716722,\n",
              " 0.01220550574362278,\n",
              " 0.004088388290256262,\n",
              " -0.037255216389894485,\n",
              " 0.00030597110162489116,\n",
              " 0.006678285542875528,\n",
              " 0.003969070501625538,\n",
              " 0.001805558567866683,\n",
              " -0.0009668248239904642,\n",
              " 0.04786748066544533,\n",
              " 0.011882646009325981,\n",
              " 0.008239944465458393,\n",
              " 0.014311113394796848,\n",
              " 0.024326786398887634,\n",
              " 0.022530002519488335,\n",
              " 0.020340168848633766,\n",
              " 0.006790584418922663,\n",
              " -0.0009685794939287007,\n",
              " -0.01204407587647438,\n",
              " -0.004611280746757984,\n",
              " -0.011391337029635906,\n",
              " 0.0294504314661026,\n",
              " -0.0006071168463677168,\n",
              " -0.0189785435795784,\n",
              " 0.01796785183250904,\n",
              " -0.02231944166123867,\n",
              " -0.0382939837872982,\n",
              " -0.0021757944487035275,\n",
              " -0.007250308990478516,\n",
              " 0.04365626350045204,\n",
              " -0.027443086728453636,\n",
              " -0.006590551696717739,\n",
              " 0.0035900610964745283,\n",
              " -0.0399223193526268,\n",
              " -0.023779328912496567,\n",
              " -0.03220175951719284,\n",
              " 0.009306785650551319,\n",
              " -0.013033711351454258,\n",
              " -0.006481762044131756,\n",
              " -0.012851225212216377,\n",
              " 0.00046893637045286596,\n",
              " 0.004930631257593632,\n",
              " -0.02224925346672535,\n",
              " 0.011243944987654686,\n",
              " -0.005344734061509371,\n",
              " -0.017827477306127548,\n",
              " -0.040820714086294174,\n",
              " 0.018473196774721146,\n",
              " -0.018866244703531265,\n",
              " 0.02529536560177803,\n",
              " 0.026544693857431412,\n",
              " -0.014430430717766285,\n",
              " -0.007390682585537434,\n",
              " 0.002568841213360429,\n",
              " -0.0007839001482352614,\n",
              " -0.033689722418785095,\n",
              " 0.006229089107364416,\n",
              " -0.01934351585805416,\n",
              " 0.001995063154026866,\n",
              " 0.0001398255117237568,\n",
              " -0.0021424556616693735,\n",
              " -0.01740635558962822,\n",
              " 0.016058767214417458,\n",
              " 0.016943123191595078,\n",
              " 0.00330053991638124,\n",
              " 0.006120299454778433,\n",
              " -0.0057377805933356285,\n",
              " -1.4736511730006896e-05,\n",
              " 0.007917084731161594,\n",
              " -0.007015182636678219,\n",
              " 0.01875394582748413,\n",
              " -0.0038848461117595434,\n",
              " -0.014177758246660233,\n",
              " 0.009931448847055435,\n",
              " 0.01622721552848816,\n",
              " -0.0382939837872982,\n",
              " -0.010787730105221272,\n",
              " -0.03155604004859924,\n",
              " 0.018866244703531265,\n",
              " 0.013981234282255173,\n",
              " 0.02032613195478916,\n",
              " 0.0234003197401762,\n",
              " -0.02398988977074623,\n",
              " -0.012921412475407124,\n",
              " 0.016943123191595078,\n",
              " 0.014683104120194912,\n",
              " 0.018150337040424347,\n",
              " -0.004849916324019432,\n",
              " -0.00397608894854784,\n",
              " -0.003286502556875348,\n",
              " -0.011152701452374458,\n",
              " 0.0034163484815508127,\n",
              " -0.016479888930916786,\n",
              " -0.04632336646318436,\n",
              " 0.010921085253357887,\n",
              " -0.045930322259664536,\n",
              " 0.011300094425678253,\n",
              " 0.0006009755306877196,\n",
              " -0.006190486252307892,\n",
              " 0.022684412077069283,\n",
              " -0.013679430820047855,\n",
              " 0.018473196774721146,\n",
              " -0.007846897467970848,\n",
              " 0.01523056160658598,\n",
              " -0.01158084161579609,\n",
              " 0.021378936246037483,\n",
              " -0.01060524396598339,\n",
              " -0.0021020981948822737,\n",
              " -0.01510422583669424,\n",
              " -0.013840860687196255,\n",
              " -0.008317150175571442,\n",
              " -0.01573590748012066,\n",
              " -0.015272674150764942,\n",
              " -0.024888282641768456,\n",
              " -0.0031584114767611027,\n",
              " -0.002674121642485261,\n",
              " -0.004758673254400492,\n",
              " -0.006871299352496862,\n",
              " 0.0037725470028817654,\n",
              " -0.01642373949289322,\n",
              " -0.0061308275908231735,\n",
              " -0.007973234169185162,\n",
              " 0.0286362636834383,\n",
              " 0.030376899987459183,\n",
              " -0.016044730320572853,\n",
              " 0.027709797024726868,\n",
              " -0.015483235009014606,\n",
              " -0.0523594431579113,\n",
              " -0.011082515120506287,\n",
              " -0.035683032125234604,\n",
              " -0.010191140696406364,\n",
              " 0.004832369275391102,\n",
              " 0.01841704733669758,\n",
              " 0.023933740332722664,\n",
              " 0.04461080580949783,\n",
              " -0.017883626744151115,\n",
              " 0.026460468769073486,\n",
              " 0.023638954386115074,\n",
              " -0.004323514178395271,\n",
              " -0.004063822794705629,\n",
              " -0.00660107983276248,\n",
              " 0.0184872355312109,\n",
              " -0.0031320913694798946,\n",
              " 0.008647028356790543,\n",
              " -0.015048075467348099,\n",
              " 0.029197759926319122,\n",
              " 0.01573590748012066,\n",
              " -0.01845915988087654,\n",
              " -0.004688486456871033,\n",
              " 0.007762673310935497,\n",
              " 0.007692486513406038,\n",
              " 0.020705141127109528,\n",
              " -0.014683104120194912,\n",
              " -0.023667030036449432,\n",
              " -0.04402123764157295,\n",
              " -0.0030601497273892164,\n",
              " -0.0035339114256203175,\n",
              " 0.01454272959381342,\n",
              " -0.0279765073210001,\n",
              " -0.0016458833124488592,\n",
              " 0.03060149773955345,\n",
              " 0.005299112759530544,\n",
              " 0.02064899168908596,\n",
              " 0.022473851218819618,\n",
              " 0.0009589287801645696,\n",
              " -0.007685468066483736,\n",
              " 0.01851530931890011,\n",
              " -0.006874809041619301,\n",
              " 0.0030987525824457407,\n",
              " -0.019624263048171997,\n",
              " -0.003807640401646495,\n",
              " -0.016802748665213585,\n",
              " -0.0029478506185114384,\n",
              " 0.03413891792297363,\n",
              " 0.018894318491220474,\n",
              " 0.03461619094014168,\n",
              " 0.0330440029501915,\n",
              " 0.011243944987654686,\n",
              " 0.01372856181114912,\n",
              " 0.00873827189207077,\n",
              " -0.011742271482944489,\n",
              " -0.017294056713581085,\n",
              " 0.007481925655156374,\n",
              " -0.03043304942548275,\n",
              " -0.012563458643853664,\n",
              " -0.01888028159737587,\n",
              " -0.017546730116009712,\n",
              " -0.010373626835644245,\n",
              " 0.010401701554656029,\n",
              " -0.0020389300771057606,\n",
              " -0.015244599431753159,\n",
              " 0.024074112996459007,\n",
              " -0.014486580155789852,\n",
              " -0.01577802002429962,\n",
              " -0.012872281484305859,\n",
              " 0.03023652546107769,\n",
              " 0.0373113676905632,\n",
              " 0.008583860471844673,\n",
              " 0.01279507577419281,\n",
              " 0.031078768894076347,\n",
              " -0.00397608894854784,\n",
              " -0.001179140293970704,\n",
              " 0.0023231871891766787,\n",
              " -0.006569495890289545,\n",
              " -0.017069458961486816,\n",
              " 0.02925390936434269,\n",
              " 0.0030040002893656492,\n",
              " -0.0029267945792526007,\n",
              " 0.014669066295027733,\n",
              " 0.0281449556350708,\n",
              " 0.02905738539993763,\n",
              " -0.040427666157484055,\n",
              " -0.028776638209819794,\n",
              " 0.005692159291356802,\n",
              " 0.010752636007964611,\n",
              " 0.038237836211919785,\n",
              " -0.018473196774721146,\n",
              " -0.004253327380865812,\n",
              " -0.01959618739783764,\n",
              " 0.011208850890398026,\n",
              " -0.030545348301529884,\n",
              " -0.0017704650526866317,\n",
              " 0.0011440467787906528,\n",
              " 0.0012572231935337186,\n",
              " -0.007980252616107464,\n",
              " 0.01757480576634407,\n",
              " 0.018711833283305168,\n",
              " -0.013840860687196255,\n",
              " 0.015118262730538845,\n",
              " 0.005864117294549942,\n",
              " 0.038265909999608994,\n",
              " -0.010752636007964611,\n",
              " -0.0038778274320065975,\n",
              " 0.0048744818195700645,\n",
              " -0.012275692075490952,\n",
              " 0.026713142171502113,\n",
              " 0.0015730643644928932,\n",
              " 0.003972579725086689,\n",
              " -0.0054780892096459866,\n",
              " 0.005330696702003479,\n",
              " -0.0005316659226082265,\n",
              " 0.006565986666828394,\n",
              " -0.012759982608258724,\n",
              " 0.029787329956889153,\n",
              " -0.033689722418785095,\n",
              " -0.00904709380120039,\n",
              " 0.012774019502103329,\n",
              " -0.00627471087500453,\n",
              " -0.007931121625006199,\n",
              " -0.0018669720739126205,\n",
              " -0.010429776273667812,\n",
              " 0.004695504903793335,\n",
              " -0.02202465571463108,\n",
              " 0.0007957442430779338,\n",
              " 0.037227142602205276,\n",
              " -0.001977516571059823,\n",
              " -0.01725194603204727,\n",
              " -0.000864615140017122,\n",
              " -0.0030794511549174786,\n",
              " -0.025744562968611717,\n",
              " -0.008169757202267647,\n",
              " 0.007390682585537434,\n",
              " -0.010450832545757294,\n",
              " -0.0359918512403965,\n",
              " 0.004534075036644936,\n",
              " 0.024705795571208,\n",
              " 0.001298458082601428,\n",
              " 0.019876936450600624,\n",
              " -0.008401374332606792,\n",
              " -0.02055072970688343,\n",
              " 0.025660337880253792,\n",
              " 0.022094842046499252,\n",
              " -0.0046533928252756596,\n",
              " -0.006415084470063448,\n",
              " 0.02202465571463108,\n",
              " -0.015244599431753159,\n",
              " -0.013770673424005508,\n",
              " 0.025632264092564583,\n",
              " -0.0035865516401827335,\n",
              " -0.01289333775639534,\n",
              " 0.02512691728770733,\n",
              " -0.010099898092448711,\n",
              " 0.0020126099698245525,\n",
              " 0.0027636101003736258,\n",
              " -0.009910393506288528,\n",
              " 0.00855578575283289,\n",
              " 0.006678285542875528,\n",
              " 0.008324168622493744,\n",
              " -0.0010563131654635072,\n",
              " 0.014711178839206696,\n",
              " 0.005674612708389759,\n",
              " -0.0025267291348427534,\n",
              " -0.01711157150566578,\n",
              " 0.028776638209819794,\n",
              " 0.013651356101036072,\n",
              " 0.008808458223938942,\n",
              " 0.0074187577702105045,\n",
              " -0.012914393097162247,\n",
              " 0.011117608286440372,\n",
              " -0.021056076511740685,\n",
              " -0.006281729321926832,\n",
              " -0.01382682379335165,\n",
              " -0.035093460232019424,\n",
              " -0.023077460005879402,\n",
              " 0.0024863716680556536,\n",
              " 0.014893664978444576,\n",
              " -0.004393701441586018,\n",
              " -0.0021828131284564734,\n",
              " -0.018403010442852974,\n",
              " 0.007229252718389034,\n",
              " -0.003170694224536419,\n",
              " 0.005481598433107138,\n",
              " 0.0056465379893779755,\n",
              " -0.0067344349808990955,\n",
              " 0.014177758246660233,\n",
              " 0.024256600067019463,\n",
              " 0.012654702179133892,\n",
              " -0.0033110680524259806,\n",
              " -0.009952505119144917,\n",
              " -0.010099898092448711,\n",
              " -0.039220452308654785,\n",
              " -0.019357552751898766,\n",
              " -0.024874243885278702,\n",
              " -0.012184449471533298,\n",
              " -0.006383500527590513,\n",
              " 0.03060149773955345,\n",
              " 0.006239617243409157,\n",
              " -0.028888937085866928,\n",
              " -0.017237907275557518,\n",
              " -0.010436794720590115,\n",
              " -0.015272674150764942,\n",
              " -0.004312986508011818,\n",
              " -0.03456003963947296,\n",
              " 0.010731580667197704,\n",
              " 0.012240598909556866,\n",
              " 0.007130991201847792,\n",
              " -0.0029934721533209085,\n",
              " 0.0296188797801733,\n",
              " -0.015048075467348099,\n",
              " 0.002238962799310684,\n",
              " -0.022866899147629738,\n",
              " 0.0035163648426532745,\n",
              " 0.012030038051307201,\n",
              " -0.025941085070371628,\n",
              " -0.01969444938004017,\n",
              " 0.03520575910806656,\n",
              " -0.020340168848633766,\n",
              " 0.004046276211738586,\n",
              " 0.03298785164952278,\n",
              " 0.0007729334756731987,\n",
              " -0.008752308785915375,\n",
              " 0.0199611596763134,\n",
              " -0.01610087975859642,\n",
              " -0.0186556838452816,\n",
              " -0.0048744818195700645,\n",
              " -0.013005636632442474,\n",
              " -0.03399854525923729,\n",
              " 0.003677794709801674,\n",
              " -0.0024898811243474483,\n",
              " -0.024874243885278702,\n",
              " 0.007804785389453173,\n",
              " 0.009447159245610237,\n",
              " -0.02542170323431492,\n",
              " -0.0015783284325152636,\n",
              " -0.011019346304237843,\n",
              " 0.017630955204367638,\n",
              " -0.0008255736320279539,\n",
              " -0.006629154551774263,\n",
              " -0.009503308683633804,\n",
              " -0.008401374332606792,\n",
              " -0.006450178101658821,\n",
              " 0.004537584260106087,\n",
              " 0.028116879984736443,\n",
              " -0.0022424720227718353,\n",
              " -0.007474907208234072,\n",
              " 0.012001963332295418,\n",
              " 0.025435740128159523,\n",
              " -0.017883626744151115,\n",
              " 0.0009062886238098145,\n",
              " 0.023652993142604828,\n",
              " -0.013047748245298862,\n",
              " -0.012444141320884228,\n",
              " 0.03405469283461571,\n",
              " -0.015202486887574196,\n",
              " 0.00044612560304813087,\n",
              " -0.020536692813038826,\n",
              " -0.010556112974882126,\n",
              " -0.01789766550064087,\n",
              " -0.030517272651195526,\n",
              " -0.006358935032039881,\n",
              " -0.021013963967561722,\n",
              " -0.02116837538778782,\n",
              " -0.0017511636251583695,\n",
              " 0.024565422907471657,\n",
              " -0.04306669533252716,\n",
              " 0.0022898484021425247,\n",
              " 0.0014256718568503857,\n",
              " -0.007152047473937273,\n",
              " -0.003293521236628294,\n",
              " -0.016142992302775383,\n",
              " -0.006471233908087015,\n",
              " -0.01245115976780653,\n",
              " -0.003667266573756933,\n",
              " 0.015062113292515278,\n",
              " -0.0019827804062515497,\n",
              " -0.022965161129832268,\n",
              " 0.022305402904748917,\n",
              " 0.01092810370028019,\n",
              " 0.012072150595486164,\n",
              " 0.01924525387585163,\n",
              " 0.21348053216934204,\n",
              " -0.02686755359172821,\n",
              " 0.020494580268859863,\n",
              " 0.019778674468398094,\n",
              " 0.023667030036449432,\n",
              " 0.024144301190972328,\n",
              " 0.009713869541883469,\n",
              " 0.017392318695783615,\n",
              " -0.008471561595797539,\n",
              " 0.0022354533430188894,\n",
              " -0.008625973016023636,\n",
              " 0.00755211291834712,\n",
              " -0.0019792711827903986,\n",
              " -0.009004982188344002,\n",
              " -0.005404392722994089,\n",
              " -0.016536038368940353,\n",
              " -0.02859415113925934,\n",
              " -0.015721870586276054,\n",
              " -0.03318437561392784,\n",
              " -0.020915701985359192,\n",
              " -0.014430430717766285,\n",
              " 0.0024144300259649754,\n",
              " -0.007545094005763531,\n",
              " -0.02542170323431492,\n",
              " 0.008836532942950726,\n",
              " 0.0077275801450014114,\n",
              " -0.004934140481054783,\n",
              " -0.002349507063627243,\n",
              " 0.00101420097053051,\n",
              " 0.02244577743113041,\n",
              " -0.021224524825811386,\n",
              " -0.0007457360625267029,\n",
              " 0.006285238545387983,\n",
              " 0.024256600067019463,\n",
              " -0.026656992733478546,\n",
              " -0.01570783369243145,\n",
              " 0.02391970343887806,\n",
              " -0.0015765737043693662,\n",
              " 0.028748562559485435,\n",
              " 0.027036001905798912,\n",
              " 0.018346861004829407,\n",
              " -0.016311440616846085,\n",
              " 0.021771982312202454,\n",
              " -0.027471160516142845,\n",
              " 0.0018599533941596746,\n",
              " 0.008092552423477173,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.array(embedding).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SiyeI-5ANup",
        "outputId": "6065478f-191f-42e2-d4be-fdefffce05ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1536,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We convert our text, such as the first text chunk containing “2023 text-generating language model,” into a vector with 1536 dimensions. By doing this for each text chunk, we can observe in a 1536-dimensional space which text chunks are closer and more similar to each other.\n",
        "\n",
        "<img src='https://miro.medium.com/v2/resize:fit:1100/format:webp/1*lssUQDyZfz3MZCpCxIh-bw.png'>"
      ],
      "metadata": {
        "id": "VDecPuDlAg0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **A commonly used distance metric is cosine similarity. So let’s try to calculate the cosine similarity between our question and the text chunks:**"
      ],
      "metadata": {
        "id": "8rg5dn1IBCxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import openai\n",
        "\n",
        "####################################################################\n",
        "# load documents\n",
        "####################################################################\n",
        "# URL of the Wikipedia page to scrape\n",
        "url = 'https://en.wikipedia.org/wiki/Prime_Minister_of_the_United_Kingdom'\n",
        "\n",
        "# Send a GET request to the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Find all the text on the page\n",
        "text = soup.get_text()\n",
        "print(len(text))\n",
        "text[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "M4SuzA-uAmc7",
        "outputId": "b7c5e6fb-06f5-4514-8044-f85068ce7efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60038\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\n\\n\\nPrime Minister of the United Kingdom - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload file\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\n Create account Log in\\n\\n\\n\\n\\n\\n\\t\\tPages for logged out editors learn more\\n\\n\\n\\nContributionsTalk\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1\\nHistory\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\nAuthority, powers and constraints\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\nConstitutional background\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\nModern premiership\\n\\n\\n\\n\\nToggle Modern premiership subsection\\n\\n\\n\\n\\n\\n4.1\\nAppointment\\n\\n\\n\\n\\n\\n\\n\\n\\n4.2\\nPrime Minister's Office\\n\\n\\n\\n\\n\\n\\n\\n\\n4.3\\nPrime Minister's Questions\\n\\n\\n\\n\\n\\n\\n\\n\\n4.4\\nSecurity and transport\\n\\n\\n\\n\\n\\n\\n\\n\\n4.5\\nInternational role\\n\\n\\n\\n\\n\\n\\n\\n\\n4.6\\nDeputy\\n\\n\\n\\n\\n\\n\\n4.6.1\\nSucc\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "####################################################################\n",
        "# split text\n",
        "####################################################################\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size = 100,\n",
        "    chunk_overlap  = 20,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([text[:1000]])\n",
        "\n",
        "####################################################################\n",
        "# calculate embeddings\n",
        "####################################################################\n",
        "# create new list with all text chunks\n",
        "text_chunks=[]\n",
        "\n",
        "for text in texts:\n",
        "    text_chunks.append(text.page_content)\n",
        "\n",
        "df = pd.DataFrame({'text_chunks': text_chunks})\n",
        "\n",
        "####################################################################\n",
        "# get embeddings from text-embedding-ada model\n",
        "####################################################################\n",
        "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "   text = text.replace(\"\\n\", \" \")\n",
        "   return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
        "\n",
        "df['ada_embedding'] = df.text_chunks.apply(lambda x: get_embedding(x, model='text-embedding-ada-002'))\n",
        "\n",
        "####################################################################\n",
        "# calculate the embeddings for the user's question\n",
        "####################################################################\n",
        "users_question = \"What is GPT-4?\"\n",
        "\n",
        "question_embedding = get_embedding(text=users_question, model=\"text-embedding-ada-002\")\n",
        "\n",
        "# create a list to store the calculated cosine similarity\n",
        "cos_sim = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "   A = row.ada_embedding\n",
        "   B = question_embedding\n",
        "\n",
        "   # calculate the cosine similarity\n",
        "   cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
        "\n",
        "   cos_sim.append(cosine)\n",
        "\n",
        "df[\"cos_sim\"] = cos_sim\n",
        "df.sort_values(by=[\"cos_sim\"], ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "liWV2TgJBSW_",
        "outputId": "5ca517fb-f785-45c2-d673-7dfeaed8264b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          text_chunks  \\\n",
              "9   4\\nModern premiership\\n\\n\\n\\n\\nToggle Modern p...   \n",
              "10  4.2\\nPrime Minister's Office\\n\\n\\n\\n\\n\\n\\n\\n\\n...   \n",
              "0    Prime Minister of the United Kingdom - Wikipedia   \n",
              "11  4.4\\nSecurity and transport\\n\\n\\n\\n\\n\\n\\n\\n\\n4...   \n",
              "6   Pages for logged out editors learn more\\n\\n\\n\\...   \n",
              "12               4.6\\nDeputy\\n\\n\\n\\n\\n\\n\\n4.6.1\\nSucc   \n",
              "2   Navigation\\n\\t\\n\\n\\nMain pageContentsCurrent e...   \n",
              "4   Search\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n...   \n",
              "3   Contribute\\n\\t\\n\\n\\nHelpLearn to editCommunity...   \n",
              "7   Contents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)...   \n",
              "1   Jump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n...   \n",
              "5   Create account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPers...   \n",
              "8   1\\nHistory\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\nAuthority, powe...   \n",
              "\n",
              "                                        ada_embedding   cos_sim  \n",
              "9   [-0.001666662865318358, 0.00393084017559886, -...  0.770997  \n",
              "10  [0.014478943310678005, 0.0020605376921594143, ...  0.754074  \n",
              "0   [0.004399775993078947, -0.01084962673485279, -...  0.739513  \n",
              "11  [0.02221507392823696, -0.020824098959565163, 0...  0.732841  \n",
              "6   [0.004999903962016106, 0.003818664001300931, 0...  0.730828  \n",
              "12  [0.009663875214755535, -0.003192658070474863, ...  0.723244  \n",
              "2   [0.0052303746342659, -0.002746198559179902, -0...  0.718181  \n",
              "4   [0.004861578810960054, 0.01493444200605154, 0....  0.717354  \n",
              "3   [0.008618349209427834, 0.009969587437808514, 0...  0.715512  \n",
              "7   [0.01620987057685852, -0.0002970777277369052, ...  0.713264  \n",
              "1   [0.014725019223988056, 0.006725178100168705, 0...  0.711432  \n",
              "5   [0.004558270331472158, -0.005939965136349201, ...  0.709929  \n",
              "8   [0.04106941446661949, -0.0023675195407122374, ...  0.704272  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-635442ad-8b99-4561-a61c-19481c33aa39\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_chunks</th>\n",
              "      <th>ada_embedding</th>\n",
              "      <th>cos_sim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4\\nModern premiership\\n\\n\\n\\n\\nToggle Modern p...</td>\n",
              "      <td>[-0.001666662865318358, 0.00393084017559886, -...</td>\n",
              "      <td>0.770997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>4.2\\nPrime Minister's Office\\n\\n\\n\\n\\n\\n\\n\\n\\n...</td>\n",
              "      <td>[0.014478943310678005, 0.0020605376921594143, ...</td>\n",
              "      <td>0.754074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Prime Minister of the United Kingdom - Wikipedia</td>\n",
              "      <td>[0.004399775993078947, -0.01084962673485279, -...</td>\n",
              "      <td>0.739513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4.4\\nSecurity and transport\\n\\n\\n\\n\\n\\n\\n\\n\\n4...</td>\n",
              "      <td>[0.02221507392823696, -0.020824098959565163, 0...</td>\n",
              "      <td>0.732841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Pages for logged out editors learn more\\n\\n\\n\\...</td>\n",
              "      <td>[0.004999903962016106, 0.003818664001300931, 0...</td>\n",
              "      <td>0.730828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4.6\\nDeputy\\n\\n\\n\\n\\n\\n\\n4.6.1\\nSucc</td>\n",
              "      <td>[0.009663875214755535, -0.003192658070474863, ...</td>\n",
              "      <td>0.723244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Navigation\\n\\t\\n\\n\\nMain pageContentsCurrent e...</td>\n",
              "      <td>[0.0052303746342659, -0.002746198559179902, -0...</td>\n",
              "      <td>0.718181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Search\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n...</td>\n",
              "      <td>[0.004861578810960054, 0.01493444200605154, 0....</td>\n",
              "      <td>0.717354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Contribute\\n\\t\\n\\n\\nHelpLearn to editCommunity...</td>\n",
              "      <td>[0.008618349209427834, 0.009969587437808514, 0...</td>\n",
              "      <td>0.715512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Contents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)...</td>\n",
              "      <td>[0.01620987057685852, -0.0002970777277369052, ...</td>\n",
              "      <td>0.713264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n...</td>\n",
              "      <td>[0.014725019223988056, 0.006725178100168705, 0...</td>\n",
              "      <td>0.711432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Create account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPers...</td>\n",
              "      <td>[0.004558270331472158, -0.005939965136349201, ...</td>\n",
              "      <td>0.709929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1\\nHistory\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\nAuthority, powe...</td>\n",
              "      <td>[0.04106941446661949, -0.0023675195407122374, ...</td>\n",
              "      <td>0.704272</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-635442ad-8b99-4561-a61c-19481c33aa39')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-635442ad-8b99-4561-a61c-19481c33aa39 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-635442ad-8b99-4561-a61c-19481c33aa39');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7d9b31e3-1bae-4b0c-83b8-ce0ef2d1aa20\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d9b31e3-1bae-4b0c-83b8-ce0ef2d1aa20')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7d9b31e3-1bae-4b0c-83b8-ce0ef2d1aa20 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 13,\n  \"fields\": [\n    {\n      \"column\": \"text_chunks\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"Create account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\n Create account Log in\",\n          \"Contents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1\\nHistory\",\n          \"4\\nModern premiership\\n\\n\\n\\n\\nToggle Modern premiership subsection\\n\\n\\n\\n\\n\\n4.1\\nAppointment\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ada_embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cos_sim\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.019198578475786845,\n        \"min\": 0.7042720251055241,\n        \"max\": 0.7709974987754566,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.7099287716319279,\n          0.7132639603015515,\n          0.7709974987754566\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Define the model you want to use**"
      ],
      "metadata": {
        "id": "zzgF1wDSA7wP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain_community # Install the missing module"
      ],
      "metadata": {
        "id": "rqRipzl4CSaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UARhcF7XC74Y",
        "outputId": "fe8bde53-c659-4053-d749-ef138cce2ff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sk-proj-t9c715UDN980ktfAHwJvT3BlbkFJ7NnyJSZ0SugFhhw0rVwM'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(openai_api_key= my_api_key, temperature=0.7)\n",
        "\n",
        "# 기본 모델 확인\n",
        "print(llm.model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMIVsDMqBshq",
        "outputId": "7f112816-f6c2-4112-feff-ebe7d3ee59b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-3.5-turbo-instruct\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = openai.Model.list()\n",
        "print([model['id'] for model in models['data']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGCYlAH8Dp2y",
        "outputId": "9b1c64ae-b45b-4e37-d418-5cec13c7ab70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dall-e-3', 'gpt-4-1106-preview', 'dall-e-2', 'tts-1-hd-1106', 'tts-1-hd', 'gpt-4o-mini-2024-07-18', 'gpt-4-0125-preview', 'babbage-002', 'gpt-4-turbo-preview', 'text-embedding-3-small', 'text-embedding-3-large', 'tts-1', 'gpt-3.5-turbo', 'whisper-1', 'gpt-4o-2024-05-13', 'text-embedding-ada-002', 'gpt-3.5-turbo-16k', 'davinci-002', 'gpt-4-turbo-2024-04-09', 'tts-1-1106', 'gpt-3.5-turbo-0125', 'gpt-4-turbo', 'gpt-3.5-turbo-1106', 'gpt-4o-mini', 'gpt-4o', 'gpt-3.5-turbo-instruct-0914', 'gpt-3.5-turbo-instruct', 'gpt-4-0613', 'gpt-4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Define our Prompt Template**"
      ],
      "metadata": {
        "id": "JGPDnv2HGMzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "# 특정 모델을 사용하도록 OpenAI LLM 초기화\n",
        "llm = ChatOpenAI(openai_api_key=my_api_key,\n",
        "                 model=\"gpt-4o-mini-2024-07-18\",\n",
        "                 temperature=0.7)\n",
        "\n",
        "# 간단한 메시지로 채팅 모델 테스트\n",
        "response = llm([HumanMessage(content=\"Hello, how are you?\")])\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88OjdsQ8CyeK",
        "outputId": "f01a03d9-330e-4503-b2c4-0dcf93210bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users_question = \"Who was the first Prime Minister of the UK?\"\n",
        "\n",
        "# 간단한 메시지로 채팅 모델 테스트\n",
        "response = llm([HumanMessage(content=users_question)])\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL6o4Y3zFOpJ",
        "outputId": "19bfb046-a7e6-4d8d-ac41-1b310740093b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first Prime Minister of the United Kingdom is generally considered to be Sir Robert Walpole. He served as First Lord of the Treasury from 1721 to 1742 and is often regarded as the de facto leader of the government during that time, although the title \"Prime Minister\" was not officially used at the time. Walpole is recognized for his significant influence over the cabinet and Parliament, effectively laying the groundwork for the modern role of the Prime Minister.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6. Creating a vector store (vector database)**\n",
        "#### **Hallucination!**"
      ],
      "metadata": {
        "id": "5fmeMJAYF4n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_question = input(\"Enter your question: \")\n",
        "\n",
        "# 간단한 메시지로 채팅 모델 테스트\n",
        "response = llm([HumanMessage(content=users_question)])\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8OEwEoaGfST",
        "outputId": "79bc25fd-3ff3-4c86-fe42-cae8193b87ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your question: 조상구에 대해 알려줘\n",
            "조상구(趙相九, 1940년 1월 30일 ~ )는 대한민국의 정치인으로, 주로 1990년대와 2000년대 초반에 활동한 인물입니다. 그는 1996년 제15대 국회의원에 선출되었으며, 이후 여러 차례 국회의원으로 활동했습니다. 조상구는 한나라당(현재의 국민의힘)의 소속으로, 보수적인 정치 성향을 가지고 있습니다.\n",
            "\n",
            "그의 정치 경력 동안 여러 가지 정책과 법안에 참여했으며, 국가의 정치 및 경제 발전에 기여하고자 노력했습니다. 또한 그는 지역사회와의 소통에도 힘썼습니다.\n",
            "\n",
            "조상구에 대한 보다 구체적인 정보나 특정 사건에 대한 질문이 있다면 말씀해 주세요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.1. Collect data that we want to use to answer the users’ questions:**\n",
        "\n",
        "<img src='https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ApbpqcZUMF-YaA6DbnVGww.png'>"
      ],
      "metadata": {
        "id": "MocfDTdrGqyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "\n",
        "text = '''\n",
        "조상구는 고려시대 명장으로 중국 수나라 100만 대군을 물리친 영웅이다.\n",
        "'''\n",
        "\n",
        "# Open a new file called 'output.txt' in write mode and store the file object in a variable\n",
        "with open('output.txt', 'w', encoding='utf-8') as file:\n",
        "    # Write the string to the file\n",
        "    file.write(text)"
      ],
      "metadata": {
        "id": "GKpL87RHHI6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.2. Load the data and define how you want to split the data into text chunks**\n",
        "\n",
        "### **PDF, Excel 등을 다양한 loader로 - Momgo DB의 Documents(Pages, metadata 로 구성)**\n",
        "\n",
        "<img src='https://miro.medium.com/v2/resize:fit:1100/format:webp/1*f5mcqjHkiz9QX63dpQnzxg.png'>"
      ],
      "metadata": {
        "id": "Lp8MZaqaHdfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# load the document\n",
        "with open('./output.txt', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# define the text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap  = 100,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([text])\n",
        "texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VbUY-vlHqo0",
        "outputId": "ad2c70bf-ad75-44bc-92d7-13c889e2897d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='조상구는 고려시대 명장으로 중국 수나라 100만 대군을 물리친 영웅이다.')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.3. Define the Embeddings Model you want to use to calculate the embeddings for your text chunks and store them in a vector store (here: Chroma)**\n",
        "\n",
        "<img src='https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ydbixXRwfgMYVdpctYTdew.png'>\n",
        "\n",
        "- **최근에는 vector DB와 더불어 Graph DB를 적용  중**"
      ],
      "metadata": {
        "id": "OArzBwLtJdca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q chromadb"
      ],
      "metadata": {
        "id": "Ss0BcFqoIoEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tiktoken"
      ],
      "metadata": {
        "id": "k9HFMf4TI32X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# define the embeddings model\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=my_api_key)\n",
        "\n",
        "# use the text chunks and the embeddings model to fill our vector store\n",
        "db = Chroma.from_documents(texts, embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xEwS7k0H3r2",
        "outputId": "249d7659-2a22-4de1-ea9d-f94c47a85050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI1g036ZIYE-",
        "outputId": "0bbf2989-56a5-418a-b27f-5aa5f13d640e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.chroma.Chroma at 0x7a42f9d15d20>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.4. Calculate the embeddings for the user’s question, find similar text chunks in our vector store and use them to build our prompt**\n",
        "\n",
        "<img src='https://miro.medium.com/v2/resize:fit:1100/format:webp/1*r2n4uA-ZlxZatnlhTVwv5Q.png'>"
      ],
      "metadata": {
        "id": "9DsHNHHZI9iS"
      }
    },
    {
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "user_question = \"조상구에 대해 알려줘\"\n",
        "\n",
        "# use our vector store to find similar text chunks\n",
        "results = db.similarity_search_with_score( # Use similarity_search_with_score directly\n",
        "    query=user_question,\n",
        "    k=5 # Pass the number of results using 'k'\n",
        ")\n",
        "\n",
        "# define the prompt template\n",
        "template = \"\"\"\n",
        "You are a chat bot who loves to help people! Given the following context sections, answer the\n",
        "question using only the given context. If you are unsure and the answer is not\n",
        "explicitly writting in the documentation, say \"Sorry, I don't know how to help with that.\"\n",
        "\n",
        "Context sections:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{users_question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"users_question\"])\n",
        "# Create an LLMChain for easier prompt management\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# fill the prompt template\n",
        "# Extract the document contents from the results\n",
        "context_contents = [doc.page_content for doc, _ in results]\n",
        "# Run the LLMChain with the formatted prompt\n",
        "response = llm_chain.run(context=context_contents, users_question=user_question)\n",
        "\n",
        "# Print the LLM's response\n",
        "print(response)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU3ayc4wKcOc",
        "outputId": "ef66e7b8-b5bf-473b-aca2-f4f8116bf5e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 5 is greater than number of elements in index 1, updating n_results = 1\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "조상구는 고려시대의 명장으로, 중국 수나라의 100만 대군을 물리친 영웅입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Summary**\n",
        "\n",
        "### - To enable our LLM to analyze and answer questions about our data, we usually don’t fine-tune the model. Instead, during **the fine-tuning process, the objective is to improve the model’s ability to effectively respond to a specific task, rather than teaching it new information.**\n",
        "\n",
        "### - In the case of Alpaca 7B, the LLM (LLaMA) was fine-tuned to behave and interact like a chatbot. The focus was on refining the model’s responses, rather than teaching it completely new information.\n",
        "\n",
        "### - So **to be able to answer questions about our own data, we use the Context Injection approach.** Creating an LLM app with Context Injection is a relatively simple process. **The main challenge lies in organizing and formatting the data to be stored in a vector database. This step is crucial for efficiently retrieving contextually similar information and ensuring reliable results.**\n",
        "\n",
        "### - The goal of the article was **to demonstrate a minimalist approach to using embedding models, vector stores**, and LLMs to process user queries. It shows how these technologies can work together to provide relevant and accurate answers, even to constantly changing facts."
      ],
      "metadata": {
        "id": "afPGclunJ5Jl"
      }
    }
  ]
}